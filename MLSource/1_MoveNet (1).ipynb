{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be67db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert path containing folders of extracted image\n",
    "dir_path = '/Users/atl/HKU/YEAR_4/COMP4081_FYP/extractedFrames_perVideo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6791043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f130d434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 12:09:28.451775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 12:09:28.459270: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-10 12:09:28.459511: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load Model from TF hub\n",
    "\n",
    "os.environ['TFHUB_CACHE_DIR'] = '/Users/atl/HKU/YEAR_4/COMP4081_FYP'\n",
    "\n",
    "module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "input_size = 192\n",
    "def movenet(input_image):\n",
    "  model = module.signatures['serving_default']\n",
    "\n",
    "  # SavedModel format expects tensor type of int32.\n",
    "  input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "  # Run model inference.\n",
    "  outputs = model(input_image)\n",
    "  # Output is a [1, 1, 17, 3] tensor.\n",
    "  keypoints_with_scores = outputs['output_0'].numpy()\n",
    "  return keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244f3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that maps from joint names to keypoint indices.\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'left_eye': 1,\n",
    "    'right_eye': 2,\n",
    "    'left_ear': 3,\n",
    "    'right_ear': 4,\n",
    "    'left_shoulder': 5,\n",
    "    'right_shoulder': 6,\n",
    "    'left_elbow': 7,\n",
    "    'right_elbow': 8,\n",
    "    'left_wrist': 9,\n",
    "    'right_wrist': 10,\n",
    "    'left_hip': 11,\n",
    "    'right_hip': 12,\n",
    "    'left_knee': 13,\n",
    "    'right_knee': 14,\n",
    "    'left_ankle': 15,\n",
    "    'right_ankle': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad742ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vid_132_extracted', 'vid_181_extracted', 'vid_148_extracted', 'vid_195_extracted', 'vid_126_extracted', 'vid_40_extracted', 'vid_89_extracted', 'vid_107_extracted', 'vid_113_extracted', 'vid_54_extracted', 'vid_169_extracted', 'vid_219_extracted', 'vid_78_extracted', 'vid_145_extracted', 'vid_151_extracted', 'vid_198_extracted', 'vid_221_extracted', 'vid_170_extracted', 'vid_200_extracted', 'vid_90_extracted', 'vid_214_extracted', 'vid_164_extracted', 'vid_46_extracted', 'vid_101_extracted', 'vid_28_extracted', 'vid_115_extracted', 'vid_52_extracted', 'vid_187_extracted', 'vid_134_extracted', 'vid_73_extracted', 'vid_120_extracted', 'vid_193_extracted', 'vid_206_extracted', 'vid_176_extracted', 'vid_31_extracted', 'vid_162_extracted', 'vid_212_extracted', 'vid_118_extracted', 'vid_143_extracted', 'vid_139_extracted', 'vid_227_extracted', 'vid_157_extracted', 'vid_194_extracted', 'vid_127_extracted', 'vid_133_extracted', 'vid_74_extracted', 'vid_180_extracted', 'vid_149_extracted', 'vid_112_extracted', 'vid_55_extracted', 'vid_218_extracted', 'vid_168_extracted', 'vid_41_extracted', 'vid_106_extracted', 'vid_220_extracted', 'vid_150_extracted', 'vid_199_extracted', 'vid_144_extracted', 'vid_91_extracted', 'vid_58_extracted', 'vid_165_extracted', 'vid_215_extracted', 'vid_201_extracted', 'vid_171_extracted', 'vid_29_extracted', 'vid_114_extracted', 'vid_53_extracted', 'vid_100_extracted', 'vid_121_extracted', 'vid_192_extracted', 'vid_186_extracted', 'vid_135_extracted', 'vid_24_extracted', 'vid_213_extracted', 'vid_0_extracted', 'vid_163_extracted', 'vid_97_extracted', 'vid_119_extracted', 'vid_177_extracted', 'vid_207_extracted', 'vid_30_extracted', 'vid_156_extracted', 'vid_226_extracted', 'vid_11_extracted', 'vid_142_extracted', 'vid_138_extracted', 'vid_38_extracted', 'vid_105_extracted', 'vid_42_extracted', 'vid_56_extracted', 'vid_111_extracted', 'vid_130_extracted', 'vid_183_extracted', 'vid_197_extracted', 'vid_124_extracted', 'vid_172_extracted', 'vid_202_extracted', 'vid_108_extracted', 'vid_216_extracted', 'vid_166_extracted', 'vid_147_extracted', 'vid_14_extracted', 'vid_153_extracted', 'vid_223_extracted', 'vid_129_extracted', 'vid_185_extracted', 'vid_71_extracted', 'vid_136_extracted', 'vid_122_extracted', 'vid_65_extracted', 'vid_191_extracted', 'vid_158_extracted', 'vid_228_extracted', 'vid_179_extracted', 'vid_209_extracted', 'vid_99_extracted', 'vid_117_extracted', 'vid_141_extracted', 'vid_188_extracted', 'vid_68_extracted', 'vid_12_extracted', 'vid_225_extracted', 'vid_155_extracted', 'vid_80_extracted', 'vid_204_extracted', 'vid_174_extracted', 'vid_160_extracted', 'vid_210_extracted', 'vid_27_extracted', 'vid_57_extracted', 'vid_110_extracted', 'vid_39_extracted', 'vid_104_extracted', 'vid_43_extracted', 'vid_196_extracted', 'vid_125_extracted', 'vid_76_extracted', 'vid_131_extracted', 'vid_182_extracted', 'vid_167_extracted', 'vid_217_extracted', 'vid_203_extracted', 'vid_173_extracted', 'vid_109_extracted', 'vid_222_extracted', 'vid_152_extracted', 'vid_128_extracted', 'vid_146_extracted', 'vid_123_extracted', 'vid_64_extracted', 'vid_229_extracted', 'vid_190_extracted', 'vid_159_extracted', 'vid_184_extracted', 'vid_70_extracted', 'vid_137_extracted', 'vid_51_extracted', 'vid_98_extracted', 'vid_116_extracted', 'vid_208_extracted', 'vid_178_extracted', 'vid_69_extracted', 'vid_13_extracted', 'vid_154_extracted', 'vid_224_extracted', 'vid_230_extracted', 'vid_140_extracted', 'vid_189_extracted', 'vid_211_extracted', 'vid_161_extracted', 'vid_26_extracted', 'vid_81_extracted', 'vid_175_extracted', 'vid_205_extracted']\n"
     ]
    }
   ],
   "source": [
    "# Get all folders\n",
    "folders = [entry for entry in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, entry))]\n",
    "folders = [folder for folder in folders if folder.startswith(\"vid_\")]\n",
    "\n",
    "# find number\n",
    "vid_nos = []\n",
    "for i in folders:\n",
    "    vid_nos.append(int(re.findall(r'\\d+', i)[0]))\n",
    "\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image.\n",
    "for i in folders:\n",
    "    imagefolder_path = os.path.join(dir_path, i)\n",
    "    data = []\n",
    "    for frame_no in tqdm(range(len([entry for entry in os.listdir(imagefolder_path) if os.path.isfile(os.path.join(imagefolder_path, entry))]))):\n",
    "        image_path = imagefolder_path+'/vid_'+re.findall(r'\\d+', i)[0]+'frame'+str(frame_no)+\".jpg\"\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image)\n",
    "        # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "        input_image = tf.expand_dims(image, axis=0)\n",
    "        input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "\n",
    "        # Run model inference.\n",
    "        keypoints_with_scores = movenet(input_image)\n",
    "        px = pd.DataFrame(keypoints_with_scores[0][0]).astype(\"float\")\n",
    "        px_flatten = px.to_numpy().flatten()\n",
    "        data.append(px_flatten)\n",
    "    df = pd.DataFrame(data, columns=['x0', 'y0', 'c0', 'x1', 'y1', 'c1', 'x2', 'y2', 'c2', \n",
    "                                    'x3', 'y3', 'c3', 'x4', 'y4', 'c4', 'x5', 'y5', 'c5', \n",
    "                                    'x6', 'y6', 'c6', 'x7', 'y7', 'c7', 'x8', 'y8', 'c8',\n",
    "                                    'x9', 'y9', 'c9', 'x10', 'y10', 'c10', 'x11', 'y11', 'c11',\n",
    "                                    'x12', 'y12', 'c12', 'x13', 'y13', 'c13', 'x14', 'y14', 'c14',\n",
    "                                    'x15', 'y15', 'c15', 'x16', 'y16', 'c16'])\n",
    "    df.to_csv(imagefolder_path+'/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['vid_67_extracted', 'vid_25_extracted', 'vid_96_extracted', 'vid_10_extracted', 'vid_17_extracted', 'vid_47_extracted', 'vid_66_extracted', 'vid_19_extracted', 'vid_63_extracted', 'vid_5_extracted', 'vid_94_extracted', 'vid_18_extracted', 'vid_4_extracted', 'vid_20_extracted', 'vid_34_extracted', 'vid_95_extracted']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9179/9179 [11:09<00:00, 13.71it/s]\n",
      "100%|██████████| 3186/3186 [03:46<00:00, 14.07it/s]\n",
      "100%|██████████| 6688/6688 [07:54<00:00, 14.09it/s]\n",
      "100%|██████████| 6463/6463 [07:42<00:00, 13.98it/s]\n",
      "100%|██████████| 5977/5977 [07:07<00:00, 13.97it/s]\n",
      "100%|██████████| 4945/4945 [05:53<00:00, 13.98it/s]\n",
      "100%|██████████| 4955/4955 [05:58<00:00, 13.81it/s]\n",
      "100%|██████████| 5056/5056 [06:10<00:00, 13.65it/s]\n",
      " 32%|███▏      | 2460/7754 [03:00<06:15, 14.12it/s]"
     ]
    }
   ],
   "source": [
    "for score_no in range(6): #no. of score subfolders; dont know how to count folders with code\n",
    "\n",
    "    dir_path = '/Users/atl/HKU/YEAR_4/COMP4081_FYP/extractedFrames_perVideo/Deadlift/Deadlift_score_'+str(score_no) #for deadlifts\n",
    "    \n",
    "    \n",
    "    # Get all folders\n",
    "    folders = [entry for entry in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, entry))]\n",
    "    folders = [folder for folder in folders if folder.startswith(\"vid_\")]\n",
    "\n",
    "    # find number\n",
    "    vid_nos = []\n",
    "    for i in folders:\n",
    "        vid_nos.append(int(re.findall(r'\\d+', i)[0]))\n",
    "    \n",
    "    print(folders)\n",
    "\n",
    "    # Load the input image.\n",
    "    for i in folders:\n",
    "        imagefolder_path = os.path.join(dir_path, i)\n",
    "        data = []\n",
    "        for frame_no in tqdm(range(len([entry for entry in os.listdir(imagefolder_path) if os.path.isfile(os.path.join(imagefolder_path, entry))]))):\n",
    "            image_path = imagefolder_path+'/vid_'+re.findall(r'\\d+', i)[0]+'frame'+str(frame_no)+\".jpg\"\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_jpeg(image)\n",
    "            # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "            input_image = tf.expand_dims(image, axis=0)\n",
    "            input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "\n",
    "            # Run model inference.\n",
    "            keypoints_with_scores = movenet(input_image)\n",
    "            px = pd.DataFrame(keypoints_with_scores[0][0]).astype(\"float\")\n",
    "            px_flatten = px.to_numpy().flatten()\n",
    "            data.append(px_flatten)\n",
    "        df = pd.DataFrame(data, columns=['x0', 'y0', 'c0', 'x1', 'y1', 'c1', 'x2', 'y2', 'c2', \n",
    "                                        'x3', 'y3', 'c3', 'x4', 'y4', 'c4', 'x5', 'y5', 'c5', \n",
    "                                        'x6', 'y6', 'c6', 'x7', 'y7', 'c7', 'x8', 'y8', 'c8',\n",
    "                                        'x9', 'y9', 'c9', 'x10', 'y10', 'c10', 'x11', 'y11', 'c11',\n",
    "                                        'x12', 'y12', 'c12', 'x13', 'y13', 'c13', 'x14', 'y14', 'c14',\n",
    "                                        'x15', 'y15', 'c15', 'x16', 'y16', 'c16'])\n",
    "        df.to_csv(imagefolder_path+'/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28160894",
   "metadata": {},
   "outputs": [],
   "source": [
    "for score_no in range(6): #no. of score subfolders; dont know how to count folders with code\n",
    "\n",
    "    dir_path = '/Users/atl/HKU/YEAR_4/COMP4081_FYP/extractedFrames_perVideo/Squat/Squat_score_'+str(score_no) #for squats\n",
    "\n",
    "    # Load the input image.\n",
    "    for i in folders:\n",
    "        imagefolder_path = os.path.join(dir_path, i)\n",
    "        data = []\n",
    "        for frame_no in tqdm(range(len([entry for entry in os.listdir(imagefolder_path) if os.path.isfile(os.path.join(imagefolder_path, entry))]))):\n",
    "            image_path = imagefolder_path+'/vid_'+re.findall(r'\\d+', i)[0]+'frame'+str(frame_no)+\".jpg\"\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_jpeg(image)\n",
    "            # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "            input_image = tf.expand_dims(image, axis=0)\n",
    "            input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "\n",
    "            # Run model inference.\n",
    "            keypoints_with_scores = movenet(input_image)\n",
    "            px = pd.DataFrame(keypoints_with_scores[0][0]).astype(\"float\")\n",
    "            px_flatten = px.to_numpy().flatten()\n",
    "            data.append(px_flatten)\n",
    "        df = pd.DataFrame(data, columns=['x0', 'y0', 'c0', 'x1', 'y1', 'c1', 'x2', 'y2', 'c2', \n",
    "                                        'x3', 'y3', 'c3', 'x4', 'y4', 'c4', 'x5', 'y5', 'c5', \n",
    "                                        'x6', 'y6', 'c6', 'x7', 'y7', 'c7', 'x8', 'y8', 'c8',\n",
    "                                        'x9', 'y9', 'c9', 'x10', 'y10', 'c10', 'x11', 'y11', 'c11',\n",
    "                                        'x12', 'y12', 'c12', 'x13', 'y13', 'c13', 'x14', 'y14', 'c14',\n",
    "                                        'x15', 'y15', 'c15', 'x16', 'y16', 'c16'])\n",
    "        df.to_csv(imagefolder_path+'/out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
